{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c96dd1",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed4a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95bfa52",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd0eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e400a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the web page\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f0a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank\n",
    "rank=[]\n",
    "try:\n",
    "    rank_tags=driver.find_element(By.XPATH, '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[1]/tbody/tr[1]/tr[0]')\n",
    "    rank.append(rank_tags.text)\n",
    "except:\n",
    "    rank.append(\"-\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897667d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver.find_elements(By.XPATH, '//*[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr')\n",
    "# Initialize a list to hold the data\n",
    "\n",
    "y_name=[]\n",
    "y_artist=[]\n",
    "y_date=[]\n",
    "y_views=[]\n",
    "ranks=[]\n",
    "# Loop through rows and collect data\n",
    "for row in rows[:]:  # Skip the header row\n",
    "    cols = row.find_elements(By.XPATH, \".//td\")\n",
    "    if len(cols) > 4:  # Ensure there are enough columns\n",
    "        \n",
    "        name = cols[0].text.strip()\n",
    "        y_name.append(name)\n",
    "        artist = cols[1].text.strip()\n",
    "        y_artist.append(artist)\n",
    "        upload_date = cols[3].text.strip()\n",
    "        y_date.append(upload_date)\n",
    "        views = cols[2].text.strip()\n",
    "        y_views.append(views)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8e1cdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"See You Again\"[20]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Shape of You\"[25]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>6.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Sugar\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[42]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Counting Stars\"[43]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[46]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Sorry\"[48]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "0                             \"Baby Shark Dance\"[7]   \n",
       "1                                   \"Despacito\"[10]   \n",
       "2                        \"Johny Johny Yes Papa\"[18]   \n",
       "3                                   \"Bath Song\"[19]   \n",
       "4                               \"See You Again\"[20]   \n",
       "5                                \"Shape of You\"[25]   \n",
       "6                           \"Wheels on the Bus\"[28]   \n",
       "7                 \"Phonics Song with Two Words\"[29]   \n",
       "8                                 \"Uptown Funk\"[30]   \n",
       "9                               \"Gangnam Style\"[31]   \n",
       "10  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11                             \"Dame Tu Cosita\"[37]   \n",
       "12   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13                                     \"Axel F\"[39]   \n",
       "14                        \"Baa Baa Black Sheep\"[40]   \n",
       "15                                      \"Sugar\"[41]   \n",
       "16                             \"Lakdi Ki Kathi\"[42]   \n",
       "17                             \"Counting Stars\"[43]   \n",
       "18                                       \"Roar\"[44]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20                      \"Shree Hanuman Chalisa\"[46]   \n",
       "21          \"Humpty the train on a fruits ride\"[47]   \n",
       "22                                      \"Sorry\"[48]   \n",
       "23                          \"Thinking Out Loud\"[49]   \n",
       "24                                    \"Perfect\"[50]   \n",
       "25                                 \"Dark Horse\"[51]   \n",
       "26                                 \"Let Her Go\"[52]   \n",
       "27                                      \"Faded\"[53]   \n",
       "28                             \"Girls Like You\"[54]   \n",
       "29                                    \"Lean On\"[55]   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                         Wiz Khalifa      April 6, 2015   \n",
       "5                                          Ed Sheeran   January 30, 2017   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                                 Psy      July 15, 2012   \n",
       "10                                        Miroshka TV  February 27, 2018   \n",
       "11                                      Ultra Records      April 5, 2018   \n",
       "12                                         Get Movies   January 31, 2012   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "15                                           Maroon 5   January 14, 2015   \n",
       "16                                       Jingle Toons      June 14, 2018   \n",
       "17                                        OneRepublic       May 31, 2013   \n",
       "18                                         Katy Perry  September 5, 2013   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "21      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "22                                      Justin Bieber   October 22, 2015   \n",
       "23                                         Ed Sheeran    October 7, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                         Katy Perry  February 20, 2014   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   14.52  \n",
       "1    8.44  \n",
       "2    6.91  \n",
       "3    6.70  \n",
       "4    6.27  \n",
       "5    6.26  \n",
       "6    6.13  \n",
       "7    5.80  \n",
       "8    5.23  \n",
       "9    5.15  \n",
       "10   5.11  \n",
       "11   4.63  \n",
       "12   4.58  \n",
       "13   4.54  \n",
       "14   4.05  \n",
       "15   4.05  \n",
       "16   4.04  \n",
       "17   4.02  \n",
       "18   4.00  \n",
       "19   3.93  \n",
       "20   3.84  \n",
       "21   3.81  \n",
       "22   3.80  \n",
       "23   3.77  \n",
       "24   3.74  \n",
       "25   3.72  \n",
       "26   3.66  \n",
       "27   3.63  \n",
       "28   3.61  \n",
       "29   3.60  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name': y_name, 'Artist': y_artist, 'Upload Date':y_date, \"Views\": y_views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5839850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca58994",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ad512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c76ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the web page\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54f64f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open International Fixture tab\n",
    "fixture=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e1b0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape A) Series B) Place C) Date D) Time\n",
    "\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7603550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrap the series title from web page\n",
    "series_tags = driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in series_tags:\n",
    "    series_name= i.text\n",
    "    series.append(series_name)\n",
    "# to scrape place\n",
    "place_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-venue ng-scope\"]')\n",
    "for i in place_tags:\n",
    "    place_name=i.text\n",
    "    place.append(place_name)\n",
    "    \n",
    "# scrape date\n",
    "date_tags = driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date_tags:\n",
    "    date_list=i.text\n",
    "    date.append(date_list)\n",
    "    \n",
    "# scrape time\n",
    "time_tags = driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tags:\n",
    "    time_m=i.text\n",
    "    time.append(time_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddbf6447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Africa Women Tour Of India Warm Up Match...</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>13 Jun</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC Mens T20 World Cup 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 Jun</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa Women Tour Of India ODI Series 2024</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>16 Jun</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa Women Tour Of India ODI Series 2024</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>19 Jun</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa Women Tour Of India ODI Series 2024</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>23 Jun</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Series  \\\n",
       "0  South Africa Women Tour Of India Warm Up Match...   \n",
       "1                        ICC Mens T20 World Cup 2024   \n",
       "2   South Africa Women Tour Of India ODI Series 2024   \n",
       "3   South Africa Women Tour Of India ODI Series 2024   \n",
       "4   South Africa Women Tour Of India ODI Series 2024   \n",
       "\n",
       "                                               Place    Date       time  \n",
       "0                   M Chinnaswamy Stadium, Bengaluru  13 Jun  13:30 IST  \n",
       "1  Central Broward Park & Broward County Stadium,...  15 Jun  20:00 IST  \n",
       "2                   M Chinnaswamy Stadium, Bengaluru  16 Jun  13:30 IST  \n",
       "3                   M Chinnaswamy Stadium, Bengaluru  19 Jun  13:30 IST  \n",
       "4                   M Chinnaswamy Stadium, Bengaluru  23 Jun  13:30 IST  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Series': series, 'Place':place, 'Date':date, 'time':time})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd15e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc3db6",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a63196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening browser\n",
    "driver= webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc70dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web page\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0023e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Economy India\n",
    "eco = driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "eco.click()\n",
    "ind= driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8279a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open GDP of states\n",
    "gdp_s=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "gdp_s.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56090607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion)\n",
    "rank=[]\n",
    "state=[]\n",
    "gsdp_1=[]\n",
    "gsdp_2=[]\n",
    "share_1=[]\n",
    "gdp_b=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f2a342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrap the rank from web page\n",
    "rank_tags = driver.find_elements(By.XPATH, '//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "for i in rank_tags[0:33]:\n",
    "    rank.append(i.text)\n",
    "    \n",
    "# to scrape state name \n",
    "state_name = driver.find_elements(By.XPATH,'//td[@class=\"name\"]')\n",
    "for i in state_name[0:33]:\n",
    "    state.append(i.text)\n",
    "    \n",
    "#to scrape gsdp1\n",
    "gsdp_1_tags = driver.find_elements(By.XPATH, '//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "for i in gsdp_1_tags[0:33]:\n",
    "    gsdp_1.append(i.text)\n",
    "    \n",
    "# to scrape gsdp2\n",
    "gsdp_2_tags=driver.find_elements(By.XPATH, '//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "for i in gsdp_2_tags[0:33]:\n",
    "    gsdp_2.append(i.text)\n",
    "    \n",
    "# To scrape share1\n",
    "share_1_tags =driver.find_elements(By.XPATH, '//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "for i in share_1_tags[0:33]:\n",
    "    share_1.append(i.text)\n",
    "    \n",
    "#to scrape gdp in billion\n",
    "gdp_b_tags =driver.find_elements(By.XPATH, '//*[@id=\"table_id\"]/tbody/tr/td[7]')\n",
    "for i in gdp_b_tags[0:33]:\n",
    "    gdp_b.append(i.text)\n",
    "\n",
    "df3 =pd.DataFrame({'Rank':rank,'State':state,'GSDP 1':gsdp_1, 'GSDP 2': gsdp_2, 'Share': share_1, 'GDP (In Billoin)': gdp_b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc10a2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 1</th>\n",
       "      <th>GSDP 2</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP (In Billoin)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>934,542</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>881,336</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>868,905</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>662,886</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>617,192</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>411,454</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>410,525</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>267,143</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>193,352</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>172,162</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>84,266</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>46,096</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>43,810</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>34,775</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,038</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State     GSDP 1     GSDP 2   Share  \\\n",
       "0     1                Maharashtra  3,108,022          -  13.17%   \n",
       "1     2                 Tamil Nadu  2,071,286  2,364,514   8.78%   \n",
       "2     3                  Karnataka  1,978,094  2,269,995   8.38%   \n",
       "3     4              Uttar Pradesh  1,975,595  2,258,040   8.37%   \n",
       "4     5                    Gujarat  1,928,683  2,230,609   8.17%   \n",
       "5     6                West Bengal  1,329,238  1,531,758   5.63%   \n",
       "6     7                  Rajasthan  1,193,489  1,365,849   5.06%   \n",
       "7     8             Andhra Pradesh  1,148,471  1,303,524   4.87%   \n",
       "8     9                  Telangana  1,124,204  1,308,034   4.76%   \n",
       "9    10             Madhya Pradesh  1,092,964  1,246,471   4.63%   \n",
       "10   11                     Kerala    934,542  1,046,188   3.96%   \n",
       "11   12                      Delhi    881,336  1,014,688   3.73%   \n",
       "12   13                    Haryana    868,905    984,055   3.68%   \n",
       "13   14                     Odisha    662,886    753,177   2.81%   \n",
       "14   15                      Bihar    650,302    751,396   2.76%   \n",
       "15   16                     Punjab    617,192    676,164   2.62%   \n",
       "16   17                      Assam    411,454    493,167   1.74%   \n",
       "17   18               Chhattisgarh    410,525    464,399   1.74%   \n",
       "18   19                  Jharkhand    358,863    393,722   1.52%   \n",
       "19   20                Uttarakhand    267,143    303,781   1.13%   \n",
       "20   21            Jammu & Kashmir    193,352    224,226   0.82%   \n",
       "21   22           Himachal Pradesh    172,162    191,728   0.73%   \n",
       "22   23                        Goa     84,266     93,672   0.36%   \n",
       "23   24                    Tripura     62,550     72,636   0.27%   \n",
       "24   25                 Chandigarh     46,096     54,285   0.20%   \n",
       "25   26                 Puducherry     43,810     49,643   0.19%   \n",
       "26   27                  Meghalaya     38,785     42,697   0.16%   \n",
       "27   28                     Sikkim     37,557     42,756   0.16%   \n",
       "28   29                    Manipur     36,594          -   0.16%   \n",
       "29   30          Arunachal Pradesh     34,775     39,630   0.15%   \n",
       "30   31                   Nagaland     31,038     35,643   0.13%   \n",
       "31   32                    Mizoram     27,824          -   0.12%   \n",
       "32   33  Andaman & Nicobar Islands     10,371          -   0.04%   \n",
       "\n",
       "   GDP (In Billoin)  \n",
       "0           414.928  \n",
       "1           276.522  \n",
       "2           264.080  \n",
       "3           263.747  \n",
       "4           257.484  \n",
       "5           177.456  \n",
       "6           159.334  \n",
       "7           153.324  \n",
       "8           150.084  \n",
       "9           145.913  \n",
       "10          124.764  \n",
       "11          117.660  \n",
       "12          116.001  \n",
       "13           88.497  \n",
       "14           86.817  \n",
       "15           82.397  \n",
       "16           54.930  \n",
       "17           54.806  \n",
       "18           47.909  \n",
       "19           35.664  \n",
       "20           25.813  \n",
       "21           22.984  \n",
       "22           11.250  \n",
       "23            8.351  \n",
       "24            6.154  \n",
       "25            5.849  \n",
       "26            5.178  \n",
       "27            5.014  \n",
       "28            4.885  \n",
       "29            4.643  \n",
       "30            4.144  \n",
       "31            3.715  \n",
       "32            1.385  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70d236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33185c8",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea8e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61e51249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening web page\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413a157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on Trending repository\n",
    "os= driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "os.click()\n",
    "trending=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f39359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapre the following A) Repository title B) Repository description C) Contributors count D) Language used\n",
    "title=[]\n",
    "desc=[]\n",
    "count=[]\n",
    "lang=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08aacff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the repository title from web page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"Link\"]')\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "    \n",
    "# to scrape the repository description\n",
    "desc_tags= driver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in desc_tags:\n",
    "    desc.append(i.text)\n",
    "    \n",
    "# to scrape Contributors count\n",
    "count_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/div[2]/a[2]')\n",
    "for i in count_tags:\n",
    "    count.append(i.text)\n",
    "    \n",
    "# to scrape Language used\n",
    "lang_tags = driver.find_elements(By.XPATH, '//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in lang_tags:\n",
    "    lang.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25065e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086115f",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6473ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46b8c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the web page\n",
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ca6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Hot-10 page \n",
    "hot= driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a')\n",
    "hot.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a3910f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the following A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board\n",
    "song=[]\n",
    "artist=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "weeks_on_board=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20997ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the song name from web page\n",
    "song_tags = driver.find_elements(By.XPATH, '//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div/ul/li/ul/li[1]')\n",
    "for i in song_tags:\n",
    "    song.append(i.text)\n",
    "    \n",
    "# Artist  name\n",
    "artist_tags= driver.find_elements(By.XPATH, '//*[@id=\"post-1479786\"]/div[3]/div/div/div/div/div/ul/li/ul/li[1]/span')\n",
    "for i in artist_tags:\n",
    "    artist.append(i.text)\n",
    "    \n",
    "# scrape Last week rank\n",
    "last_week_rank_tags=driver.find_elements(By.XPATH, '//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div/ul/li/ul/li[4]/span')\n",
    "for i in last_week_rank_tags:\n",
    "    last_week_rank.append(i.text)\n",
    "    \n",
    "# scrape peak rank\n",
    "peak_rank_tags =driver.find_elements(By.XPATH, '//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[5]/span')\n",
    "for i in peak_rank_tags:\n",
    "    peak_rank.append(i.text)\n",
    "    \n",
    "# scrape weeks on board\n",
    "weeks_on_board_tags = driver.find_elements(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[6]/span')\n",
    "for i in weeks_on_board_tags:\n",
    "    weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d6aa59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(song), len(artist), len(weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "245a09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf5c75",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18ace754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b10d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web page\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "224b2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape A) Book name B) Author name C) Volumes sold D) Publisher E) Genre\n",
    "name=[]\n",
    "author=[]\n",
    "volumes=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5285e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the name from web page\n",
    "name_tags = driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[2]')\n",
    "for i in name_tags:\n",
    "    name.append(i.text)\n",
    "    \n",
    "# To scrape author\n",
    "author_tags=driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[3]')\n",
    "for i in author_tags:\n",
    "    author.append(i.text)\n",
    "    \n",
    "# to scrape volumes\n",
    "volumes_tags= driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[4]')\n",
    "for i in volumes_tags:\n",
    "    volumes.append(i.text)\n",
    "    \n",
    "# to scrape genre\n",
    "publisher_tags= driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[5]')\n",
    "for i in publisher_tags:\n",
    "    publisher.append(i.text)\n",
    "\n",
    "# to scrape genre\n",
    "genre_tags= driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[6]')\n",
    "for i in genre_tags:\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afe7bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(name), len(author), len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1f8a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1a60c",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d6820eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a44d7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open web page\n",
    "driver.get('https://www.imdb.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07b67b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on menu\n",
    "menu= driver.find_element(By.XPATH, '/html/body/div[2]/nav/div[2]/label[1]/span')\n",
    "menu.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "896c9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_pop=driver.find_element(By.XPATH, '/html/body/div[2]/nav/div[2]/aside[1]/div/div[2]/div/div[2]/div[1]/span/div/div/ul/a[3]/span')\n",
    "most_pop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6759c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes\n",
    "name=[]\n",
    "span=[]\n",
    "genre=[]\n",
    "run=[]\n",
    "ratings=[]\n",
    "votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "740d429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the name from web page\n",
    "name_tags = driver.find_elements(By.XPATH, '//div[@class=\"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-b189961a-9 iALATN cli-title\"]')\n",
    "for i in name_tags:\n",
    "    name.append(i.text)\n",
    "    \n",
    "# to scrape the span from web page\n",
    "span_tags = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/div[3]/section/div/div[2]/div/ul/li/div[2]/div/div/div[3]/span[1]')\n",
    "for i in span_tags:\n",
    "    span.append(i.text)\n",
    "    \n",
    "# to scrape the genre from web page\n",
    "genre_tags = driver.find_elements(By.XPATH, '//span[@class=\"sc-b189961a-3 hidKPx cli-title-type-data\"]')\n",
    "for i in genre_tags:\n",
    "    genre.append(i.text)\n",
    "    \n",
    "# to scrape the runtime from web page\n",
    "run_tags = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/div[3]/section/div/div[2]/div/ul/li/div/div/div/div[3]/span[2]')\n",
    "for i in run_tags:\n",
    "    run.append(i.text)\n",
    "    \n",
    "# to scrape the ratings from web page\n",
    "ratings_tags = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div/div[3]/section/div/div[2]/div/ul/li/div/div/div/span/div/span')\n",
    "for i in ratings_tags:\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# to scrape the votes from web page\n",
    "votes_tags = driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star--voteCount\"]')\n",
    "for i in votes_tags:\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a05082d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(name), len(span), len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6645ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d0e44",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n",
    "ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9e48ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d04b792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open web page\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7f23b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all data set\n",
    "data_set=driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a')\n",
    "data_set.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dacdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "name=[]\n",
    "d_type=[]\n",
    "task=[]\n",
    "att_type=[]\n",
    "no_inst=[]\n",
    "no_attri=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09874b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrape the name from web page\n",
    "name_tags = driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in name_tags:\n",
    "    name.append(i.text)\n",
    "    \n",
    "# to scrape the data type from web page\n",
    "d_type_tags = driver.find_elements(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div/div/div/div[2]/span')\n",
    "for i in d_type_tags:\n",
    "    d_type.append(i.text)\n",
    "    \n",
    "# to scrape the task from web page\n",
    "task_tags = driver.find_elements(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div/div/div/div[1]')\n",
    "for i in task_tags:\n",
    "    task.append(i.text)\n",
    "    \n",
    "# to scrape the attribute type from web page\n",
    "att_type_tags = driver.find_elements(By.XPATH, '//table[@class=\"col-span-full my-2 table sm:col-start-2\"]/tbody/tr/td[2]')\n",
    "for i in att_type_tags:\n",
    "    att_type.append(i.text)\n",
    "    \n",
    "# to scrape the attribute type from web page\n",
    "no_inst_tags = driver.find_elements(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div/div/div/div/div[3]/span')\n",
    "for i in no_inst_tags:\n",
    "    no_inst.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aaff0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(d_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94382493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
