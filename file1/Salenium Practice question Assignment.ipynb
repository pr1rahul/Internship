{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfc94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557595c",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17eca289",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07558432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the webpage\n",
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0f8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#designation\n",
    "designation=driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f316381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location\n",
    "location=driver.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f342544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search\n",
    "search_job=driver.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "search_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9c591d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a16f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrap the job title from web page\n",
    "title_tags=driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# to scrap the job location \n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# to scrap the company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#to scrap the experience required\n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ded9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33fbc3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst , Senior Data Analyst , Data Anal...</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>appsoft solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>valenta bpo solutions pvt. ltd.</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Power BI, Python, SQL)- Internal...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>talent leads hr solutions pvt ltd</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst Fresher and Experience Vacancy</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst Opening</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Governance Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>white horse manpower consultancy (p...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0  Data Analyst , Senior Data Analyst , Data Anal...   Bangalore\\n+8   \n",
       "1                                       Data Analyst       Bangalore   \n",
       "2  Data Analyst (Power BI, Python, SQL)- Internal...       Bangalore   \n",
       "3        Data Analyst Fresher and Experience Vacancy  Bangalore\\n+12   \n",
       "4                               Data Analyst Opening  Bangalore\\n+12   \n",
       "5                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "6                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "7                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "8                                   Business Analyst   Bangalore\\n+6   \n",
       "9                            Data Governance Analyst       Bangalore   \n",
       "\n",
       "                                  Company Experience_Required  \n",
       "0                       appsoft solutions          0 to 4 Yrs  \n",
       "1         valenta bpo solutions pvt. ltd.          4 to 5 Yrs  \n",
       "2       talent leads hr solutions pvt ltd          3 to 8 Yrs  \n",
       "3                     radhika enterprises          0 to 4 Yrs  \n",
       "4                     radhika enterprises          0 to 4 Yrs  \n",
       "5                           techno endura           0 to 1 Yr  \n",
       "6                     radhika enterprises          0 to 4 Yrs  \n",
       "7                     radhika enterprises          0 to 4 Yrs  \n",
       "8  mackenzie modern it solutions priva...          4 to 6 Yrs  \n",
       "9  white horse manpower consultancy (p...          5 to 8 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company':company_name,'Experience_Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ec53b",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for ““Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fded0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b96decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web page\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1321e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designation\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65dbf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ce5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search\n",
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bce81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "600f9f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#To scrap job title\n",
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# To scrap the job location\n",
    "location_tags= driver.find_elements(By.XPATH,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#To scrap the company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\" row2\"]/span/a[1]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#To scrap experience required\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "    \n",
    "print(len(job_title),len(job_location),len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c818538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist, Marketing</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Hyderabad, Pune, Bengaluru</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Hyderabad, Pune, Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist-Senior Associate - P&amp;T Labs</td>\n",
       "      <td>Mumbai, Hyderabad, Bengaluru</td>\n",
       "      <td>PwC Service Delivery Center</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Bengaluru, Delhi / NCR</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore Rural, Kolkata, Mumbai (All Areas)</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NLP Data Scientist - Real World Data (RWD)</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Agilite Global Solutions</td>\n",
       "      <td>7-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>Hybrid - Pune, Gurugram, Bengaluru</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0                   Data Scientist, Marketing   \n",
       "1                              Data Scientist   \n",
       "2                              Data Scientist   \n",
       "3  Data Scientist-Senior Associate - P&T Labs   \n",
       "4                              Data Scientist   \n",
       "5                              Data Scientist   \n",
       "6  NLP Data Scientist - Real World Data (RWD)   \n",
       "7                      Data Science Associate   \n",
       "8                              Data Scientist   \n",
       "9                         Lead Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "1                Hybrid - Hyderabad, Pune, Bengaluru   \n",
       "2                Hybrid - Hyderabad, Pune, Bengaluru   \n",
       "3                       Mumbai, Hyderabad, Bengaluru   \n",
       "4                     Mumbai, Bengaluru, Delhi / NCR   \n",
       "5       Bangalore Rural, Kolkata, Mumbai (All Areas)   \n",
       "6  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "7                 Hybrid - Pune, Gurugram, Bengaluru   \n",
       "8                           Pune, Chennai, Bengaluru   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                           Company Experience_Required  \n",
       "0                         Coursera             4-6 Yrs  \n",
       "1                    Tech Mahindra            6-10 Yrs  \n",
       "2                          Infosys             4-8 Yrs  \n",
       "3      PwC Service Delivery Center             4-6 Yrs  \n",
       "4                         Deloitte             4-9 Yrs  \n",
       "5  Tata Consultancy Services (TCS)             5-9 Yrs  \n",
       "6         Agilite Global Solutions             7-8 Yrs  \n",
       "7                    ZS Associates             1-3 Yrs  \n",
       "8                            Wipro            6-11 Yrs  \n",
       "9                     Baker Hughes            9-14 Yrs  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company':company_name,'Experience_Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8720e",
   "metadata": {},
   "source": [
    "Q3: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses. Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce2fcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e970cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open webpage\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "379ada1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sunglasses in field where “search for products, brands and more” is written \n",
    "product=driver.find_element(By.CLASS_NAME,'Pke_EE')\n",
    "product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f24baa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search\n",
    "search=driver.find_element(By.CLASS_NAME,'_2iLD__')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c27ae375",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "598d7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    #To scrap the brand name\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"syl9yP\"]')\n",
    "    for i in brand_tags:\n",
    "        brand_list=i.text\n",
    "        if len(brand)>99:\n",
    "            pass\n",
    "        else:\n",
    "            brand.append(brand_list)\n",
    "        \n",
    "    \n",
    "    # To scrap the product description\n",
    "    product_des_tags= driver.find_elements(By.XPATH,'//div[@class=\"hCKiGj\"]/a[1]')\n",
    "    for i in product_des_tags:\n",
    "        product_des=i.text\n",
    "        if len(product_description)>99:\n",
    "            pass\n",
    "        else:\n",
    "            product_description.append(product_des)\n",
    "            \n",
    "    #To scrap the price\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"Nx9bqj\"]')\n",
    "    for i in price_tags:\n",
    "        price_list=i.text\n",
    "        if len(price)>99:\n",
    "            pass\n",
    "        else:\n",
    "            price.append(price_list)\n",
    "                \n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55da9db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
