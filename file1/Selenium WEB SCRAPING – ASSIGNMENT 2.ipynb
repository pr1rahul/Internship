{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1effc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0548d8",
   "metadata": {},
   "source": [
    "Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a50e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening web browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a047c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the web page\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffb67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designation\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "769e3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[7]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf921a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying location filter\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[4]/div[2]/div[1]/label/i\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2357d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying salary filter\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1766db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list to scrap the 10 data values\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f22afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrap the job title from web page\n",
    "title_tags = driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for i in title_tags[0:10]:\n",
    "    title= i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#to scrap the job location from web page\n",
    "location_tags=driver.find_elements(By.XPATH, '//span[@class=\"locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# to scrap the company name from the web page\n",
    "company_tags=driver.find_elements(By.XPATH, '//div[@class=\" row2\"]/span/a[1]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# to scrap the experience required from web page\n",
    "experience_tags=driver.find_elements(By.XPATH, '//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experince=i.text\n",
    "    experience_required.append(experince)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f43d925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist HTHD</td>\n",
       "      <td>Bengaluru, Kolkata, Mumbai, New Delhi, Hyderab...</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru, Gurugram</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MACHINE LEARNING / DATA SCIENCE TRAINER</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Ethnotech Academy</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Nestle</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Inmobi Solutions</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Alcon Laboratories</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru, Kolkata, Mumbai, New Delhi, Hyderab...</td>\n",
       "      <td>Digital Glyde</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>Bengaluru, Kolkata, Mumbai, New Delhi, Hyderab...</td>\n",
       "      <td>Wizaltia Hr Solutions</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title  \\\n",
       "0                      Data Scientist HTHD   \n",
       "1                           Data Scientist   \n",
       "2                           Data Scientist   \n",
       "3                    Senior Data Scientist   \n",
       "4  MACHINE LEARNING / DATA SCIENCE TRAINER   \n",
       "5                           Data Scientist   \n",
       "6                     Staff Data Scientist   \n",
       "7                           Data Scientist   \n",
       "8                           Data Scientist   \n",
       "9                    Python Data Scientist   \n",
       "\n",
       "                                            Location           Company Name  \\\n",
       "0  Bengaluru, Kolkata, Mumbai, New Delhi, Hyderab...                   Ford   \n",
       "1                                Bengaluru, Gurugram              Blackbuck   \n",
       "2                                          Bengaluru      Applied Materials   \n",
       "3                                          Bengaluru                Siemens   \n",
       "4                                          Bengaluru      Ethnotech Academy   \n",
       "5                                          Bengaluru                 Nestle   \n",
       "6                                          Bengaluru       Inmobi Solutions   \n",
       "7                                          Bengaluru     Alcon Laboratories   \n",
       "8  Bengaluru, Kolkata, Mumbai, New Delhi, Hyderab...          Digital Glyde   \n",
       "9  Bengaluru, Kolkata, Mumbai, New Delhi, Hyderab...  Wizaltia Hr Solutions   \n",
       "\n",
       "  Experience Required  \n",
       "0             1-4 Yrs  \n",
       "1             3-7 Yrs  \n",
       "2             2-4 Yrs  \n",
       "3             3-8 Yrs  \n",
       "4             2-5 Yrs  \n",
       "5             2-4 Yrs  \n",
       "6             3-6 Yrs  \n",
       "7             2-3 Yrs  \n",
       "8             3-7 Yrs  \n",
       "9             2-7 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe\n",
    "df=pd.DataFrame({\"Title\": job_title, \"Location\": job_location, \"Company Name\": company_name,\"Experience Required\": experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e0b21",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4cb0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opeining web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a4dff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First get the webpage https://www.shine.com/\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ef9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "designation = driver.find_element(By.CLASS_NAME, \"form-control  \")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b6f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location\n",
    "location=driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "241b0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click the searchbutton.\n",
    "search_job=driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "search_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d51ef9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the data for job_title, job_location, company_name, experience_required\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db043243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "#scrap job title\n",
    "title_tags=driver.find_elements(By.XPATH, '//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scrap job location\n",
    "location_tags=driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scrap company name\n",
    "company_tags=driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scrap experience required\n",
    "experience_tags=driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dda223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e56afdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst , Senior Data Analyst , Data Anal...</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>appsoft solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>valenta bpo solutions pvt. ltd.</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Power BI, Python, SQL)- Internal...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>talent leads hr solutions pvt ltd</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst Opening</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Fresher and Experience Vacancy</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MIS Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>quess corp (magna infotech)</td>\n",
       "      <td>8 to 13 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0  Data Analyst , Senior Data Analyst , Data Anal...   Bangalore\\n+8   \n",
       "1                                       Data Analyst       Bangalore   \n",
       "2  Data Analyst (Power BI, Python, SQL)- Internal...       Bangalore   \n",
       "3                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "4                               Data Analyst Opening  Bangalore\\n+12   \n",
       "5        Data Analyst Fresher and Experience Vacancy  Bangalore\\n+12   \n",
       "6                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "7                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "8                                   Business Analyst   Bangalore\\n+6   \n",
       "9                                        MIS Analyst       Bangalore   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                       appsoft solutions          0 to 4 Yrs  \n",
       "1         valenta bpo solutions pvt. ltd.          4 to 5 Yrs  \n",
       "2       talent leads hr solutions pvt ltd          3 to 8 Yrs  \n",
       "3                           techno endura           0 to 1 Yr  \n",
       "4                     radhika enterprises          0 to 4 Yrs  \n",
       "5                     radhika enterprises          0 to 4 Yrs  \n",
       "6                     radhika enterprises          0 to 4 Yrs  \n",
       "7                     radhika enterprises          0 to 4 Yrs  \n",
       "8  mackenzie modern it solutions priva...          4 to 6 Yrs  \n",
       "9             quess corp (magna infotech)         8 to 13 Yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Title\":job_title,\"Location\":job_location,\"Company Name\": company_name,\"Experience Required\": experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1b6c7",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a962c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web browser\n",
    "driver= webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c78405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening web page\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c268a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the 1. Rating, 2. Review summary, and 3. Full Review for first 100 reviews\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599162b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap for first 100 reviews\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start, end):\n",
    "    # rating\n",
    "    rating_tags=driver.find_elements(By.XPATH, '//div[@class=\"XQDdHH Ga3i8K\"]')\n",
    "    for i in rating_tags:\n",
    "        rating_list=i.text\n",
    "        if len(rating)>99:\n",
    "            pass\n",
    "        else:\n",
    "            rating.append(rating_list)\n",
    "            \n",
    "    # review_summary        \n",
    "    summary_tags=driver.find_elements(By.XPATH,'//p[@class=\"z9E0IG\"]')\n",
    "    for i in summary_tags:\n",
    "        summary_list=i.text\n",
    "        if len(review_summary)>99:\n",
    "            pass\n",
    "        else:\n",
    "            review_summary.append(summary_list)\n",
    "    \n",
    "    #full review\n",
    "    review_tags=driver.find_elements(By.XPATH,'//div[@class=\"ZmyHeo\"]')\n",
    "    for i in review_tags:\n",
    "        review_list=i.text\n",
    "        if len(full_review)>99:\n",
    "            pass\n",
    "        else:\n",
    "            full_review.append(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee82246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b731064",
   "metadata": {},
   "source": [
    "Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3676f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49918332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening webpage\n",
    "driver.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260370f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search \"sneakers\" in the search field\n",
    "product = driver.find_element(By.CLASS_NAME,'Pke_EE')\n",
    "product.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e37f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click search button\n",
    "search_button=driver.find_element(By.CLASS_NAME,'_2iLD__')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95f1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap the data for first 100 sneakers\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10955988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to scrap the first 100 sneakers we have to visit 3 pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    #brand\n",
    "    brand_tags=driver.find_elements(By.XPATH, '//div[@class=\"syl9yP\"]')\n",
    "    for i in brand_tags:\n",
    "        brand_list=i.text\n",
    "        if len(brand)>99:\n",
    "            pass\n",
    "        else:\n",
    "            brand.append(brand_list)\n",
    "            \n",
    "    #product description\n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"WKTcLC\"]')\n",
    "    for i in product_tags:\n",
    "        product_list=i.text\n",
    "        if len(product_description)>99:\n",
    "            pass\n",
    "        else:\n",
    "            product_description.append(product_list)\n",
    "            \n",
    "    #price\n",
    "    price_tags=driver.find_elements(By.XPATH, '//div[@class=\"Nx9bqj\"]')\n",
    "    for i in price_tags:\n",
    "        price_list=i.text\n",
    "        if len(price)>99:\n",
    "            pass\n",
    "        else:\n",
    "            price.append(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30cb173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand), len(product_description), len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb22aeb",
   "metadata": {},
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53aaa40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c740dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web page\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6ddbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search 'Laptop'\n",
    "product=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "product.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5872aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click search icon\n",
    "search_icon=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4227a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting CPU Type filter to “Intel Core i7” \n",
    "filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[19]/span/span[11]/li/span/a/div/label/i')\n",
    "filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e35b6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "\n",
    "title=[]\n",
    "ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db8c2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape title\n",
    "title_tags=driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title_list=i.text\n",
    "    title.append(title_list)\n",
    "    \n",
    "# scrape ratings\n",
    "ratings_tags=driver.find_elements(By.XPATH, '//i[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')\n",
    "for i in ratings_tags[0:10]:\n",
    "    rating_list=i.text\n",
    "    ratings.append(rating_list)\n",
    "    \n",
    "#scrape price\n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price_list=i.text\n",
    "    price.append(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb49d58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title), len(ratings), len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f02ad38",
   "metadata": {},
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on Top Quote\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cd49ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d945d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening webpage \n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "260d20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top quotes\n",
    "top_quotes=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3e6b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap a) Quote b) Author c) Type Of Quotes\n",
    "quote=[]\n",
    "author=[]\n",
    "quote_type=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "490867b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Top 1000 quotes of all time\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start, end):\n",
    "    # quote\n",
    "    quote_tags=driver.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        quote_list=i.text\n",
    "        if len(quote)>999:\n",
    "            pass\n",
    "        else:\n",
    "            quote.append(quote_list)\n",
    "        \n",
    "    # author\n",
    "    author_tags=driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        author_list=i.text\n",
    "        if len(author)>999:\n",
    "            pass\n",
    "        else:\n",
    "            author.append(author_list)\n",
    "         \n",
    "    #Type of quotes\n",
    "    quote_types_tags=driver.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "    for i in quote_types_tags:\n",
    "        quote_types_list=i.text\n",
    "        if len(quote_type)>999:\n",
    "            pass\n",
    "        else:\n",
    "            quote_type.append(quote_types_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d04bb1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(quote), len(author), len(quote_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b0829",
   "metadata": {},
   "source": [
    "Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\n",
    "scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92a84c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web page\n",
    "driver.get('https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6753af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cb29cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5417089a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S.N.\\nPM Name\\nBorn-Dead\\nTerm of office\\nRema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'Name': 'S.N.', 'Born-Dead': 'PM Name', 'Term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'Name': 'S.N.\n",
       "PM Name\n",
       "Born-Dead\n",
       "Term of offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'Name': '1.', 'Born-Dead': 'Jawahar Lal Nehru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'Name': '1.', 'Born-Dead': 'Jawahar Lal Nehru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'Name': 'Jawahar Lal Nehru', 'Born-Dead': '(1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  S.N.\\nPM Name\\nBorn-Dead\\nTerm of office\\nRema...\n",
       "1  {'Name': 'S.N.', 'Born-Dead': 'PM Name', 'Term...\n",
       "2  {'Name': 'S.N.\n",
       "PM Name\n",
       "Born-Dead\n",
       "Term of offic...\n",
       "3  {'Name': '1.', 'Born-Dead': 'Jawahar Lal Nehru...\n",
       "4  {'Name': '1.', 'Born-Dead': 'Jawahar Lal Nehru...\n",
       "5  {'Name': 'Jawahar Lal Nehru', 'Born-Dead': '(1..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051377f",
   "metadata": {},
   "source": [
    "Q8: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b286fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open browser\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0c3c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open web page\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a853cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search 50 most expensive cars\n",
    "product=driver.find_element(By.XPATH,'/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "product.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48056959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search button\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[9]/div[6]/form/input[2]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03a9f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on '50 most expensive cars'\n",
    "option=driver.find_element(By.XPATH,'/html/body/div[9]/div[9]/div/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb17aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape car name and price\n",
    "car_name=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb3d6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the 50 most expensive cars\n",
    "car_tags = driver.find_elements(By.XPATH, '//h3[@class=\"subheader\"]')\n",
    "for i in car_tags[0:50]:\n",
    "    car= i.text\n",
    "    car_name.append(car)\n",
    "\n",
    "#to scrap the price from web page\n",
    "price_tags=driver.find_elements(By.XPATH, '//strong')\n",
    "for i in price_tags[0:50]:\n",
    "    price_l=i.text\n",
    "    price.append(price_l)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10ad1211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb5126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5ca67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
